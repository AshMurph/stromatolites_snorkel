{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro. to Snorkel: Extracting Spouse Relations from the News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part IV: Training a Model with Data Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the tutorial, we will train a statistical model to differentiate between true and false `Spouse` mentions.\n",
    "\n",
    "We will train this model using _data programming_, and we will **ignore** the training labels provided with the training data. This is a more realistic scenario; in the wild, hand-labeled training data is rare and expensive. Data programming enables us to train a model using only a modest amount of hand-labeled data for validation and testing. For more information on data programming, see the [NIPS 2016 paper](https://arxiv.org/abs/1605.07723)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os,sys\n",
    "os.environ['SNORKELDB']=\"postgres:///stromatolite\"\n",
    "\n",
    "import numpy as np\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "StromStrat = candidate_subclass('StromStrat', ['strom', 'stratname'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat our definition of the `Spouse` `Candidate` subclass from Parts II and III."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading `CandidateSet` objects\n",
    "\n",
    "We reload the training and development `CandidateSet` objects from the previous parts of the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "train_candidates = session.query(CandidateSet).filter(CandidateSet.name == 'Training Candidates').one()\n",
    "print len(train)\n",
    "test_candidates = session.query(CandidateSet).filter(CandidateSet.name == 'Test Candidates').one()\n",
    "print len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatically Creating Features\n",
    "Recall that our goal is to distinguish between true and false mentions of spouse relations. To train a model for this task, we first embed our `Spouse` candidates in a feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import FeatureManager\n",
    "\n",
    "feature_manager = FeatureManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a new feature set- note that we _create_ a set of features based on the training candidates, and then featurize the test set using this set of features (using _update_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time F_train = feature_manager.create(session, train, 'Training Features')\n",
    "F_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time F_test = feature_manager.update(session, test, 'Training Features', False)\n",
    "F_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OR** if we've already created one, we can simply load as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F_train = feature_manager.load(session, train_candidates, 'Training Features')\n",
    "F_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F_test = feature_manager.load(session, test_candidates, 'Training Features')\n",
    "F_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the returned matrix is a special subclass of the `scipy.sparse.csr_matrix` class, with some special features which we demonstrate below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F_train.get_candidate(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F_train.get_key(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Labeling Functions\n",
    "Labeling functions are a core tool of data programming. They are heuristic functions that aim to classify candidates correctly. Their outputs will be automatically combined and denoised to estimate the probabilities of training labels for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from snorkel.lf_helpers import is_inverted,get_left_tokens, get_right_tokens, get_between_tokens, get_text_between, get_tagged_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Labeling Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we construct a `LabelManager`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelManager\n",
    "label_manager = LabelManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we run the `LabelManager` to to apply the labeling functions to the training `CandidateSet`.  We'll start with some of our labeling functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "all_c = session.query(CandidateSet).filter(CandidateSet.name == 'Candidate Set').one()\n",
    "\n",
    "for c in all_c:\n",
    "    if c[0].parent_id==11996:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import yaml, psycopg2\n",
    "from snorkel.models import Span\n",
    "\n",
    "good_words={'strom':{'present','found','abundant'},'strat':{'contain','contains','include','includes'}}\n",
    "\n",
    "# Connect to Postgres\n",
    "\"\"\"\n",
    "with open('../credentials', 'r') as credential_yaml:\n",
    "    credentials = yaml.load(credential_yaml)\n",
    "with open('../config', 'r') as config_yaml:\n",
    "    config = yaml.load(config_yaml)\n",
    "\"\"\"\n",
    "\n",
    "# Connect to Postgres\n",
    "connection = psycopg2.connect(\n",
    "    dbname= 'stromatolite' #credentials['snorkel_postgres']['database'],\n",
    "    #user=credentials['snorkel_postgres']['user'],\n",
    "    #password=credentials['snorkel_postgres']['password'],\n",
    "    #host=credentials['snorkel_postgres']['host'],\n",
    "    #port=credentials['snorkel_postgres']['port'])\n",
    "    )\n",
    "cursor = connection.cursor()\n",
    "\n",
    "\n",
    "def LF_num_stratphrase(c):\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT distinct span.id from span \n",
    "        JOIN strom_strat on span.id=strom_strat.stratname_id  \n",
    "        WHERE span.parent_id=%(parent_id)s;\"\"\",\n",
    "                   {\"parent_id\": c[0].parent.id\n",
    "                    })\n",
    "    tmp_span=cursor.fetchall()\n",
    "\n",
    "    tmp_strat = session.query(Span).filter(Span.id.in_(tmp_span)).all()\n",
    "    num_strat = len({a.get_span() for a in tmp_strat})\n",
    "\n",
    "    return -1 if num_strat > 1 else 1\n",
    "\n",
    "test=LF_num_stratphrase(c)\n",
    "print test\n",
    "\n",
    "def LF_wordsep_forty(c):\n",
    "    ws = len(get_between_tokens(c))\n",
    "    return -1 if ws > 40 else 0\n",
    "\n",
    "test=LF_wordsep_forty(c)\n",
    "print test\n",
    "\n",
    "\n",
    "def LF_wordsep_twenty(c):\n",
    "    ws = len(get_between_tokens(c))\n",
    "    return -1 if ws > 20 and ws <= 40 else 0\n",
    "\n",
    "test=LF_wordsep_twenty(c)\n",
    "print test\n",
    "\n",
    "def LF_wordsep_ten(c):\n",
    "    ws = len(get_between_tokens(c))\n",
    "    return -1 if ws > 10 and ws <= 20 else 0\n",
    "\n",
    "test=LF_wordsep_ten(c)\n",
    "print test\n",
    "\n",
    "\n",
    "def LF_nlp_parent(c):\n",
    "    strom_parent = c[0].get_attrib_tokens('dep_parents')\n",
    "    strom_idx = [c[0].get_word_start()+1,c[0].get_word_end()+1]\n",
    "\n",
    "    strat_parent = c[1].get_attrib_tokens('dep_parents')\n",
    "    strat_idx = [c[1].get_word_start()+1,c[1].get_word_end()+1]\n",
    "    \n",
    "    nlp_check = [True for a in strom_idx if a in strat_parent] + [True for a in strat_idx if a in strom_parent]\n",
    "    return 0 if not nlp_check else 1\n",
    "\n",
    "test=LF_nlp_parent(c)\n",
    "print test\n",
    "\n",
    "def LF_goodwords(c):\n",
    "    if is_inverted(c):\n",
    "        if len(good_words['strat'].intersection(set(get_between_tokens(c)))) > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        if len(good_words['strom'].intersection(set(get_between_tokens(c)))) > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "test=LF_goodwords(c)\n",
    "print test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LFs = [\n",
    "    #LF_num_stratphrase,\n",
    "    LF_wordsep_forty,\n",
    "    LF_wordsep_twenty,\n",
    "    LF_wordsep_ten,\n",
    "    LF_nlp_parent,\n",
    "    LF_goodwords\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%time L_train = label_manager.create(session, train_candidates, 'Training LF Labels', f=LFs)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OR** load if we've already created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time L_train = label_manager.load(session, train_candidates, 'LF Labels')\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view statistics about the resulting label matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_train.lf_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Generative Model\n",
    "We estimate the accuracies of the labeling functions without supervision. Specifically, we estimate the parameters of a `NaiveBayes` generative model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import NaiveBayes\n",
    "\n",
    "gen_model = NaiveBayes()\n",
    "gen_model.train(L_train, n_iter=10000, rate=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply the generative model to the training candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_model.w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Discriminative Model\n",
    "We use the estimated probabilites to train a discriminative model that classifies each `Candidate` as a true or false mention. We'll use a random hyperparameter search, evaluated on the development set labels, to find the best hyperparameters for our model. To run a hyperparameter search, we need labels for a development set. If they aren't already available, we can manually create labels using the Viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import LogReg\n",
    "disc_model = LogReg(bias_term=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: Here, we're training our model with hand-tuned hyperparameters... another option (the better one at some point) is to use some of our ground-truth-labeled candidates to serve as a \"dev set\" to automatically tune the model hyperparameters.  See the tutorial for this**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "disc_model.train(F_train, train_marginals, n_iter=1000, rate=0.01, mu=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring against the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_gold_test = label_manager.load(session, test_candidates, 'iross')\n",
    "L_gold_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tp, fp, tn, fn = disc_model.score(F_test, L_gold_test, set_unlabeled_as_neg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing Examples\n",
    "After evaluating on the development `CandidateSet`, the labeling functions can be modified. Try changing the labeling functions to improve performance. You can view the true positives, false positives, true negatives, and false negatives using the `Viewer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.viewer import SentenceNgramViewer\n",
    "\n",
    "sv = SentenceNgramViewer(fn, session)\n",
    "sv"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
